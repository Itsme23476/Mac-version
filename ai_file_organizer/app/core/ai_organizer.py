"""
AI-powered file organization planner.
LLM proposes → App validates → User approves → App executes

Core Principle: The LLM must never directly modify files.
- LLM plans
- App validates
- User approves
- App executes
"""

import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

logger = logging.getLogger(__name__)

# ─────────────────────────────────────────────────────────────
# PROMPTS
# ─────────────────────────────────────────────────────────────

ORGANIZATION_SCHEMA = """{
  "folders": {
    "<folder-name>": [<file_id>, <file_id>, ...],
    ...
  }
}"""

SYSTEM_PROMPT = f"""You are a file organization assistant. Given a user's instruction and files with metadata, propose how to organize them into folders.

CRITICAL: FOLLOW USER INSTRUCTIONS LITERALLY
- The user's instruction is the PRIMARY directive - follow it EXACTLY
- If user says "move all files to X" or "put all files in X", put ALL files in folder "X" - no exceptions
- Do NOT organize by file type unless the user specifically asks for it
- Do NOT create additional folders beyond what the user requested

FRESH START ON EVERY REQUEST:
- Each instruction is a NEW organization request - ignore any existing folder structure
- Files may currently be in subfolders - IGNORE their current location
- Treat ALL files as if they are in a flat list, ready to be organized from scratch

FILE INFORMATION PROVIDED:
- id: unique file identifier (use this in your response)
- name: the filename (may include path like "subfolder/file.txt" - IGNORE the path, use only the filename)
- ext: the FILE EXTENSION (e.g., .mp4, .json, .png, .pdf)
- label/tags/caption: AI-generated descriptions

STRICT RULES:
1. Return ONLY valid JSON matching this schema:
{ORGANIZATION_SCHEMA}

2. folder-name: use EXACTLY what the user specifies, or lowercase kebab-case if organizing by type
3. Use ONLY file_ids from the provided list - NEVER invent IDs
4. EVERY file_id must appear in exactly ONE folder
5. Maximum 2 folder levels
6. Do NOT rename files - only organize into folders
7. NEVER return empty folders - every folder must have at least one file

INSTRUCTION INTERPRETATION:

SIMPLE MOVE INSTRUCTIONS (e.g., "move all files to X", "put everything in X", "move files to folder called X"):
- Put ALL files in the single folder the user specified
- Do NOT create any other folders
- Do NOT organize by type - just move everything to that one folder
- Example: "move all files to hello" → {{"folders": {{"hello": [1, 2, 3, 4, 5, ...]}}}}

TYPE-BASED INSTRUCTIONS (e.g., "organize by type", "sort files by extension", "put videos in videos folder"):
- Only then organize files by their type/extension
- Use file extensions to determine type

MIXED INSTRUCTIONS (e.g., "put screenshots in screenshots, organize rest by type"):
- Follow the specific instruction for mentioned types
- Organize remaining files by type

JSON only. No markdown. No explanation. No prose."""


# ─────────────────────────────────────────────────────────────
# FILE SUMMARY FOR LLM
# ─────────────────────────────────────────────────────────────

def _infer_file_type_hints(file_name: str) -> List[str]:
    """
    Infer file type hints from filename patterns.
    This helps the AI identify files even without proper tags.
    """
    hints = []
    name_lower = file_name.lower()
    
    # Screenshot patterns
    if any(p in name_lower for p in ['screenshot', 'screen shot', 'screen_shot', 'snip', 'capture']):
        hints.append('screenshot')
    
    # Invoice/Receipt patterns
    if any(p in name_lower for p in ['invoice', 'receipt', 'bill', 'payment']):
        hints.append('invoice/receipt')
    
    # Document patterns
    if any(p in name_lower for p in ['document', 'doc', 'report', 'letter', 'contract']):
        hints.append('document')
    
    # Photo patterns
    if any(p in name_lower for p in ['img_', 'dsc_', 'photo', 'pic_', 'image']):
        hints.append('photo')
    
    # Video patterns  
    if any(p in name_lower for p in ['vid_', 'video', 'mov_', 'clip']):
        hints.append('video')
    
    # Download patterns
    if any(p in name_lower for p in ['download', 'downloaded']):
        hints.append('download')
    
    return hints


def build_file_summary(files: List[Dict[str, Any]], max_files: int = 300) -> str:
    """
    Create a compact summary of files for the LLM context.
    Limits tokens while preserving key metadata.
    Also includes file extension for accurate type matching.
    """
    lines = []
    for f in files[:max_files]:
        fid = f.get('id')
        name = f.get('file_name', 'unknown')[:50]
        label = f.get('label', '') or ''
        caption = (f.get('caption', '') or '')[:80]
        tags = f.get('tags', []) or []
        
        # Extract file extension for accurate type matching
        ext = ''
        if '.' in name:
            ext = name[name.rfind('.'):].lower()
        
        # Add inferred hints from filename patterns
        hints = _infer_file_type_hints(name)
        all_tags = list(tags[:8]) + hints
        tags_str = ', '.join(all_tags) if all_tags else ''
        
        # Include extension prominently so AI can match file types
        line = f"id:{fid} | {name} | ext:{ext} | label:{label} | tags:[{tags_str}]"
        if caption:
            line += f" | caption:{caption}"
        lines.append(line)
    
    summary = "\n".join(lines)
    
    if len(files) > max_files:
        summary += f"\n... and {len(files) - max_files} more files"
    
    return summary


# ─────────────────────────────────────────────────────────────
# LLM REQUEST
# ─────────────────────────────────────────────────────────────

def request_organization_plan(
    user_instruction: str,
    files: List[Dict[str, Any]],
) -> Optional[Dict[str, Any]]:
    """
    Send user instruction + file metadata to LLM.
    Returns the proposed plan as a dict, or None on failure.
    
    The LLM acts only as a planner - it never executes anything.
    """
    from .settings import settings
    
    if not files:
        logger.warning("No files provided for organization")
        return None
    
    file_summary = build_file_summary(files)
    
    # Detect auto-organize mode vs specific instruction mode
    is_auto_organize = user_instruction.startswith("[AUTO-ORGANIZE]")
    
    if is_auto_organize:
        # Auto-organize: MUST include ALL files, follow user instruction LITERALLY
        user_message = f"""User instruction: "{user_instruction}"

Files to organize ({len(files)} total):
{file_summary}

CRITICAL - FOLLOW THE INSTRUCTION LITERALLY:
- If the instruction says "move all files to X" or "put files in folder X", put ALL {len(files)} files in folder "X"
- Do NOT organize by file type unless explicitly asked
- Do NOT create extra folders - only create what the user asked for
- You MUST include EVERY file_id in your response
- Each file_id must appear in exactly ONE folder
- Total files in your response must equal {len(files)}

Example: If instruction is "move all files to hello", return: {{"folders": {{"hello": [list all {len(files)} file IDs here]}}}}

Propose an organization plan. Return JSON only."""
    else:
        # Specific instruction: organize ALL files based on instruction
        user_message = f"""User instruction: "{user_instruction}"

Files to organize ({len(files)} total):
{file_summary}

CRITICAL - FRESH ORGANIZATION:
- This is a NEW organization request - ignore any existing folder structure
- Treat ALL files as if starting fresh from a flat list
- Organize ALL {len(files)} files according to the user's instruction
- If user says "move all files to X", put ALL files in folder "X"
- If user specifies a structure, follow it and put remaining files in appropriate folders
- NEVER return empty folders - always include all files
- Every file_id must appear exactly once in your response

Propose an organization plan. Return JSON only."""

    provider = settings.ai_provider
    
    if provider == 'openai':
        return _request_openai(user_message)
    elif provider == 'local':
        return _request_ollama(user_message)
    else:
        logger.warning("No AI provider configured")
        return None


def request_plan_refinement(
    original_instruction: str,
    current_plan: Dict[str, Any],
    feedback: str,
    files: List[Dict[str, Any]],
) -> Optional[Dict[str, Any]]:
    """
    Refine an existing plan based on user feedback.
    Returns the updated plan as a dict, or None on failure.
    """
    from .settings import settings
    
    if not current_plan:
        logger.warning("No plan to refine")
        return None
    
    file_summary = build_file_summary(files)
    
    # Format current plan for context
    current_plan_json = json.dumps(current_plan, indent=2)
    
    user_message = f"""Original instruction: "{original_instruction}"

Current plan:
{current_plan_json}

User feedback: "{feedback}"

Files available ({len(files)} total):
{file_summary}

Based on the user feedback, provide an UPDATED organization plan.
Apply the user's requested changes to the current plan.
Return the complete updated plan as JSON only."""

    provider = settings.ai_provider
    
    if provider == 'openai':
        return _request_openai(user_message)
    elif provider == 'local':
        return _request_ollama(user_message)
    else:
        logger.warning("No AI provider configured")
        return None


def _request_openai(user_message: str) -> Optional[Dict[str, Any]]:
    """Request plan via OpenAI API through Supabase Edge Function proxy."""
    try:
        from .vision import _call_openai_proxy
        
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_message},
        ]
        
        # Call OpenAI via Supabase Edge Function proxy
        resp_data = _call_openai_proxy("chat", messages, max_tokens=4000, temperature=0.1)
        
        if not resp_data:
            logger.error("OpenAI proxy returned no data for organization plan")
            return None
        
        # Extract content from OpenAI response format
        choices = resp_data.get("choices", [])
        if not choices:
            logger.warning("OpenAI response has no choices")
            return None
        
        content = choices[0].get("message", {}).get("content", "")
        if not content:
            logger.warning("OpenAI response has no content")
            return None
        
        logger.info(f"OpenAI organization response (truncated): {content[:300]}")
        return _parse_json(content)
    except Exception as e:
        logger.error(f"OpenAI organization request failed: {e}")
        return None


def _request_ollama(user_message: str) -> Optional[Dict[str, Any]]:
    """Request plan via local Ollama."""
    import requests
    from .vision import OLLAMA_URL, get_local_model, _ollama_is_alive
    
    if not _ollama_is_alive():
        logger.warning("Ollama not running")
        return None
    
    payload = {
        "model": get_local_model(),
        "prompt": SYSTEM_PROMPT + "\n\n" + user_message,
        "stream": False,
        "temperature": 0.1,
    }
    
    try:
        r = requests.post(f"{OLLAMA_URL}/api/generate", json=payload, timeout=180)
        if r.ok:
            content = r.json().get("response", "")
            logger.info(f"Ollama organization response (truncated): {content[:300]}")
            return _parse_json(content)
    except Exception as e:
        logger.error(f"Ollama organization request failed: {e}")
    return None


def _parse_json(content: str) -> Optional[Dict[str, Any]]:
    """Parse JSON from LLM response, handling markdown wrapping."""
    # Try direct parse first
    try:
        return json.loads(content)
    except:
        pass
    
    # Try extracting JSON from markdown code block
    if "```" in content:
        import re
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
    
    # Try finding JSON object in the content
    start = content.find("{")
    end = content.rfind("}")
    if start != -1 and end > start:
        try:
            return json.loads(content[start:end+1])
        except:
            pass
    
    logger.error("Failed to parse JSON from LLM response")
    return None


def deduplicate_plan(plan: Dict[str, Any]) -> Dict[str, Any]:
    """
    Remove duplicate file_ids from the plan.
    If a file appears in multiple folders, keep only the first occurrence.
    This handles cases where the AI mistakenly puts the same file in multiple folders.
    """
    if not plan or "folders" not in plan:
        return plan
    
    seen_ids = set()
    duplicates_removed = 0
    cleaned_folders = {}
    
    for folder_name, file_ids in plan.get("folders", {}).items():
        if not isinstance(file_ids, list):
            continue
        
        cleaned_ids = []
        for fid in file_ids:
            try:
                fid_int = int(fid)
                if fid_int not in seen_ids:
                    seen_ids.add(fid_int)
                    cleaned_ids.append(fid_int)
                else:
                    duplicates_removed += 1
                    logger.debug(f"Removed duplicate file_id {fid_int} from folder '{folder_name}'")
            except (TypeError, ValueError):
                # Keep invalid IDs for validation to catch
                cleaned_ids.append(fid)
        
        if cleaned_ids:
            cleaned_folders[folder_name] = cleaned_ids
    
    if duplicates_removed > 0:
        logger.warning(f"Removed {duplicates_removed} duplicate file_id(s) from AI plan")
    
    return {"folders": cleaned_folders}


def ensure_all_files_included(plan: Dict[str, Any], all_file_ids: set, files_info: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Ensure all provided file IDs are included in the plan.
    
    If the AI missed any files, automatically add them to a 'misc' folder.
    This prevents files from being left unorganized in auto-organize mode.
    
    Args:
        plan: The organization plan from AI
        all_file_ids: Set of all file IDs that should be in the plan
        files_info: Optional list of file info dicts for better folder selection
        
    Returns:
        Updated plan with all files included
    """
    if not plan or "folders" not in plan:
        plan = {"folders": {}}
    
    # Collect all file IDs currently in the plan
    included_ids = set()
    for folder_name, file_ids in plan.get("folders", {}).items():
        for fid in file_ids:
            try:
                included_ids.add(int(fid))
            except (TypeError, ValueError):
                pass
    
    # Find missing file IDs
    missing_ids = all_file_ids - included_ids
    
    if not missing_ids:
        return plan  # All files are included
    
    logger.warning(f"AI plan missing {len(missing_ids)} file(s). Adding them to 'misc' folder.")
    
    # Log which files are missing for debugging
    if files_info:
        missing_names = []
        for f in files_info:
            try:
                if int(f.get('id', 0)) in missing_ids:
                    missing_names.append(f.get('file_name', 'unknown'))
            except (TypeError, ValueError):
                pass
        if missing_names:
            logger.info(f"Missing files: {', '.join(missing_names[:10])}")
    
    # Add missing files to 'misc' folder
    folders = plan.get("folders", {})
    
    # Use 'misc' if it exists, otherwise create it
    misc_folder = None
    for name in ['misc', 'other', 'unsorted']:
        if name in folders:
            misc_folder = name
            break
    
    if misc_folder is None:
        misc_folder = 'misc'
        folders[misc_folder] = []
    
    # Add missing IDs to misc folder
    for missing_id in missing_ids:
        folders[misc_folder].append(missing_id)
    
    logger.info(f"Added {len(missing_ids)} missing file(s) to '{misc_folder}' folder")
    
    return {"folders": folders}


# ─────────────────────────────────────────────────────────────
# VALIDATION (MANDATORY - App is the final authority)
# ─────────────────────────────────────────────────────────────

def validate_plan(
    plan: Dict[str, Any],
    valid_file_ids: set,
    max_depth: int = 2
) -> Tuple[bool, List[str]]:
    """
    Validate the organization plan for safety.
    
    This is the critical safety gate - the app validates everything
    before any file operation occurs.
    
    Checks:
    - All file_ids exist in our database
    - No duplicates across folders
    - Folder depth is limited
    - No system/root folders touched
    - No path traversal attacks
    
    Returns: (is_valid, list_of_errors)
    """
    errors = []
    
    if not plan:
        errors.append("Plan is empty")
        return False, errors
    
    folders = plan.get("folders")
    if not folders or not isinstance(folders, dict):
        errors.append("Plan must contain 'folders' dict")
        return False, errors
    
    seen_ids = set()
    
    for folder_name, file_ids in folders.items():
        # Safety checks on folder name
        if not folder_name or not isinstance(folder_name, str):
            errors.append(f"Invalid folder name: {folder_name}")
            continue
        
        # Prevent path traversal
        if ".." in folder_name:
            errors.append(f"Path traversal not allowed: {folder_name}")
            continue
        
        # Prevent absolute paths
        if folder_name.startswith("/") or folder_name.startswith("\\"):
            errors.append(f"Absolute paths not allowed: {folder_name}")
            continue
        
        # Windows drive letters
        if ":" in folder_name:
            errors.append(f"Drive letters not allowed: {folder_name}")
            continue
        
        # Check for system folder names
        dangerous_names = {'system32', 'windows', 'program files', 'programdata', '$recycle.bin'}
        if folder_name.lower() in dangerous_names:
            errors.append(f"System folder name not allowed: {folder_name}")
            continue
        
        # Check depth
        depth = folder_name.replace("\\", "/").count("/") + 1
        if depth > max_depth:
            errors.append(f"Folder too deep ({depth} > {max_depth}): {folder_name}")
        
        # Validate file IDs
        if not isinstance(file_ids, list):
            errors.append(f"Folder '{folder_name}' must have list of file IDs")
            continue
        
        for fid in file_ids:
            # Ensure fid is an integer
            try:
                fid_int = int(fid)
            except (TypeError, ValueError):
                errors.append(f"Invalid file_id type: {fid}")
                continue
            
            if fid_int not in valid_file_ids:
                errors.append(f"Unknown file_id: {fid_int}")
            elif fid_int in seen_ids:
                errors.append(f"Duplicate file_id: {fid_int} (appears in multiple folders)")
            seen_ids.add(fid_int)
    
    return len(errors) == 0, errors


# ─────────────────────────────────────────────────────────────
# CONVERT PLAN TO MOVE OPERATIONS
# ─────────────────────────────────────────────────────────────

def plan_to_moves(
    plan: Dict[str, Any],
    files_by_id: Dict[int, Dict[str, Any]],
    destination_root: Path
) -> List[Dict[str, Any]]:
    """
    Convert validated plan to concrete move operations.
    
    This is deterministic - no AI involved here.
    The app fully controls what actually happens.
    """
    moves = []
    skipped_not_found = 0
    skipped_no_info = 0
    skipped_already_in_dest = 0
    
    for folder_name, file_ids in plan.get("folders", {}).items():
        dest_folder = destination_root / folder_name
        
        for fid in file_ids:
            # Normalize fid to int
            try:
                fid_int = int(fid)
            except (TypeError, ValueError):
                logger.warning(f"Invalid file ID type: {fid}")
                continue
            
            file_info = files_by_id.get(fid_int)
            if not file_info:
                skipped_no_info += 1
                logger.debug(f"No file info for ID {fid_int}")
                continue
            
            source_path = Path(file_info['file_path'])
            if not source_path.exists():
                skipped_not_found += 1
                logger.debug(f"Source file doesn't exist: {source_path}")
                continue
            
            dest_path = dest_folder / source_path.name
            
            # Skip files that are already in the destination folder
            # This prevents "moving" files to where they already are
            if source_path.parent.resolve() == dest_folder.resolve():
                skipped_already_in_dest += 1
                logger.debug(f"Skipping {source_path.name} - already in destination folder {dest_folder}")
                continue
            
            # Also skip if the exact destination file already exists and is the same file
            if dest_path.exists() and source_path.resolve() == dest_path.resolve():
                skipped_already_in_dest += 1
                logger.debug(f"Skipping {source_path.name} - source and destination are the same file")
                continue
            
            # Handle collisions by adding numeric suffix (only for different files)
            counter = 1
            original_stem = source_path.stem
            original_suffix = source_path.suffix
            while dest_path.exists():
                dest_path = dest_folder / f"{original_stem} ({counter}){original_suffix}"
                counter += 1
            
            moves.append({
                "file_id": fid_int,
                "file_name": source_path.name,
                "source_path": str(source_path),
                "destination_path": str(dest_path),
                "destination_folder": folder_name,
                "size": file_info.get('file_size', 0),
            })
    
    # Log summary
    total_in_plan = sum(len(fids) for fids in plan.get("folders", {}).values())
    logger.info(f"plan_to_moves: {len(moves)} valid moves from {total_in_plan} files in plan. "
                f"Skipped: {skipped_not_found} not found, {skipped_no_info} no info, "
                f"{skipped_already_in_dest} already in destination")
    
    return moves


# ─────────────────────────────────────────────────────────────
# UTILITY FUNCTIONS
# ─────────────────────────────────────────────────────────────

def get_plan_summary(plan: Dict[str, Any], files_by_id: Dict[int, Dict[str, Any]]) -> Dict[str, Any]:
    """
    Get a human-readable summary of the organization plan.
    """
    folders = plan.get("folders", {})
    
    total_files = sum(len(fids) for fids in folders.values())
    total_size = 0
    
    folder_summaries = []
    for folder_name, file_ids in folders.items():
        folder_size = 0
        for fid in file_ids:
            try:
                fid_int = int(fid)
                file_info = files_by_id.get(fid_int, {})
                folder_size += file_info.get('file_size', 0)
            except:
                pass
        total_size += folder_size
        
        folder_summaries.append({
            "name": folder_name,
            "file_count": len(file_ids),
            "size_bytes": folder_size,
            "size_mb": round(folder_size / (1024 * 1024), 2),
        })
    
    return {
        "total_folders": len(folders),
        "total_files": total_files,
        "total_size_bytes": total_size,
        "total_size_mb": round(total_size / (1024 * 1024), 2),
        "folders": folder_summaries,
    }
